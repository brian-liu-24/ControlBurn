{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import sys\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pmlb import fetch_data\n",
    "from pmlb import classification_dataset_names, regression_dataset_names\n",
    "from sklearn.feature_selection import  RFE\n",
    "from itertools import repeat\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from ControlBurn.ControlBurnExperiment import build_trees_bag_experiment\n",
    "from ControlBurn.ControlBurnExperiment import solve_step_experiment\n",
    "\n",
    "from ControlBurn.ControlBurnExperiment import plot_tradeoff_curve\n",
    "from ControlBurn.RandomForestBaseline import RandomForestBaseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment Comparing Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "error\n",
      "1\n",
      "error\n",
      "2\n",
      "error\n",
      "3\n",
      "error\n",
      "4\n",
      "error\n",
      "5\n",
      "error\n",
      "6\n",
      "error\n",
      "7\n",
      "error\n",
      "8\n",
      "error\n",
      "9\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "names = ['Hill_Valley_with_noise', 'Hill_Valley_without_noise',\n",
    "       'analcatdata_bankruptcy', 'analcatdata_boxing2',\n",
    "       'analcatdata_cyyoung8092', 'analcatdata_cyyoung9302',\n",
    "       'analcatdata_japansolvent', 'analcatdata_lawsuit', 'appendicitis',\n",
    "       'australian', 'biomed', 'breast_cancer_wisconsin', 'buggyCrx',\n",
    "       'bupa', 'chess', 'churn', 'clean1', 'cleve', 'colic', 'credit_a',\n",
    "       'crx', 'diabetes', 'dis', 'glass2', 'haberman', 'heart_c',\n",
    "       'horse_colic', 'hypothyroid', 'ionosphere', 'lupus', 'phoneme',\n",
    "       'pima', 'prnn_crabs', 'prnn_synth', 'ring', 'sonar', 'spambase',\n",
    "       'spectf', 'tokyo1', 'twonorm', 'wdbc']\n",
    "\n",
    "data_details = pd.read_csv('../Data/pmlb_meta.csv')\n",
    "pmlb = data_details[data_details['dataset'].isin(names)]\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "n = 0\n",
    "while n < 10:\n",
    "    print(n)\n",
    "    try:\n",
    "        nfeat = []\n",
    "        NAME_time = []\n",
    "        baseline_time = []\n",
    "        rfe_time = []\n",
    "\n",
    "        for name in names:\n",
    "            data = fetch_data(name)\n",
    "            data = data.sample(1000,replace = True)\n",
    "            y = data['target']\n",
    "            X = data.drop('target',axis = 1)\n",
    "\n",
    "            nfeat.append(len(X.columns))\n",
    "            max_depth= 10\n",
    "            problem_type = 'Classification'\n",
    "            loss_type = 'logistic'\n",
    "            optimization_type = 'penalized'\n",
    "            lambd=  0.014\n",
    "            \n",
    "            if name in ['Hill_Valley_with_noise','Hill_Valley_without_noise']:\n",
    "                lambd = 0.004\n",
    "            if name == 'clean1':\n",
    "                lambd = 0.005\n",
    "\n",
    "            threshold= 10**-3\n",
    "            ntrials = 10\n",
    "            features_to_find = min(len(X.columns),10)\n",
    "\n",
    "            xTrain,xTest,yTrain,yTest= train_test_split(  X, y, test_size=0.33)\n",
    "            arg = [xTrain,yTrain,xTest,yTest, max_depth,problem_type,loss_type,lambd,threshold,optimization_type]\n",
    "\n",
    "            ts = time.time()\n",
    "            \n",
    "            tree = build_trees_bag_experiment(arg)\n",
    "            res = solve_step_experiment(arg,tree)\n",
    "            nfeatures = res[2]\n",
    "            \n",
    "            te = time.time()\n",
    "            NAME_time.append(te-ts)\n",
    "\n",
    "            ts = time.time()\n",
    "            model = RandomForestClassifier(n_estimators = 100)\n",
    "            rf = model.fit(xTrain,yTrain)\n",
    "            imp = pd.DataFrame(np.column_stack((xTrain.columns,rf.feature_importances_)),columns = ['features','scores']).sort_values('scores',ascending = False)\n",
    "            to_use = imp.head(nfeatures)['features'].values\n",
    "            rf1 = model.fit(xTrain[to_use],yTrain)\n",
    "            pred = rf1.predict_proba(xTest[to_use])[:,1]    \n",
    "            te = time.time()\n",
    "\n",
    "            baseline_time.append(te-ts)\n",
    "            ts = time.time()\n",
    "            selector = RFE(RandomForestClassifier(n_estimators = 100), n_features_to_select=nfeatures, step=1)\n",
    "            selector = selector.fit(xTrain, yTrain)\n",
    "            selector.support_\n",
    "            te = time.time()\n",
    "            rfe_time.append(te-ts)\n",
    "            temp = np.column_stack((nfeat,NAME_time,baseline_time,rfe_time))\n",
    "            temp = pd.DataFrame(temp,columns = ['features','name','baseline','RFE'])\n",
    "            results = results.append(temp)\n",
    "            \n",
    "    except:\n",
    "        print('error')\n",
    "    n = n+1\n",
    "\n",
    "#Store Results\n",
    "results = results[results['features']<10]\n",
    "rfe_to_plot = []\n",
    "control_burn_to_plot = []\n",
    "for i in np.sort(results['features'].unique()):\n",
    "        control_burn_to_plot.append(results[results['features'] == i]['name'])\n",
    "        rfe_to_plot.append(results[results['features'] == i]['RFE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hill_Valley_with_noise\n",
      "Hill_Valley_without_noise\n",
      "analcatdata_bankruptcy\n",
      "analcatdata_boxing2\n",
      "analcatdata_cyyoung8092\n",
      "analcatdata_cyyoung9302\n",
      "analcatdata_japansolvent\n",
      "analcatdata_lawsuit\n",
      "appendicitis\n",
      "australian\n",
      "biomed\n",
      "breast_cancer_wisconsin\n",
      "buggyCrx\n",
      "bupa\n",
      "chess\n",
      "churn\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8e122937b23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mto_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mrf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[1;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 304\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "    nfeat = []\n",
    "    NAME_time = []\n",
    "    baseline_time = []\n",
    "    rfe_time = []\n",
    "\n",
    "    for name in names:\n",
    "        print(name)\n",
    "        data = fetch_data(name)\n",
    "        data = data.sample(1000,replace = True)\n",
    "        y = data['target']\n",
    "        X = data.drop('target',axis = 1)\n",
    "\n",
    "        nfeat.append(len(X.columns))\n",
    "        max_depth= 10\n",
    "        problem_type = 'Classification'\n",
    "        loss_type = 'logistic'\n",
    "        optimization_type = 'penalized'\n",
    "        lambd=  0.014\n",
    "            \n",
    "        if name in ['Hill_Valley_with_noise','Hill_Valley_without_noise']:\n",
    "            lambd = 0.004\n",
    "        if name == 'clean1':\n",
    "            lambd = 0.005\n",
    "\n",
    "        threshold= 10**-3\n",
    "        ntrials = 10\n",
    "        features_to_find = min(len(X.columns),10)\n",
    "\n",
    "        xTrain,xTest,yTrain,yTest= train_test_split(  X, y, test_size=0.33)\n",
    "        arg = [xTrain,yTrain,xTest,yTest, max_depth,problem_type,loss_type,lambd,threshold,optimization_type]\n",
    "\n",
    "        ts = time.time()\n",
    "\n",
    "        tree = build_trees_bag_experiment(arg)\n",
    "        res = solve_step_experiment(arg,tree)\n",
    "        nfeatures = res[2]\n",
    "            \n",
    "        te = time.time()\n",
    "        NAME_time.append(te-ts)\n",
    "\n",
    "        ts = time.time()\n",
    "        model = RandomForestClassifier(n_estimators = 100)\n",
    "        rf = model.fit(xTrain,yTrain)\n",
    "        imp = pd.DataFrame(np.column_stack((xTrain.columns,rf.feature_importances_)),columns = ['features','scores']).sort_values('scores',ascending = False)\n",
    "        to_use = imp.head(nfeatures)['features'].values\n",
    "        rf1 = model.fit(xTrain[to_use],yTrain)\n",
    "        pred = rf1.predict_proba(xTest[to_use])[:,1]    \n",
    "        te = time.time()\n",
    "\n",
    "        baseline_time.append(te-ts)\n",
    "        ts = time.time()\n",
    "        selector = RFE(RandomForestClassifier(n_estimators = 100), n_features_to_select=nfeatures, step=1)\n",
    "        selector = selector.fit(xTrain, yTrain)\n",
    "        selector.support_\n",
    "        te = time.time()\n",
    "        rfe_time.append(te-ts)\n",
    "        temp = np.column_stack((nfeat,NAME_time,baseline_time,rfe_time))\n",
    "        temp = pd.DataFrame(temp,columns = ['features','name','baseline','RFE'])\n",
    "        results = results.append(temp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], 0.5, 0, 0.5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax  = fig.add_subplot(111)\n",
    "plt.violinplot(rfe_to_plot, positions = np.sqrt(results['features'].unique()),showextrema=False)\n",
    "plt.violinplot(control_burn_to_plot , positions =  np.sqrt(results['features'].unique()),showextrema= False)\n",
    "plt.ylabel('Computation Time in Seconds')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.xticks([3,4,5,6,7,8,9,10],[9,16,25,36,49,65,81,100])\n",
    "labels = []\n",
    "def add_label(violin, label,hatch = None):\n",
    "    color = violin[\"bodies\"][0].get_facecolor().flatten()\n",
    "    labels.append((mpatches.Patch(color=color,hatch = hatch), label))\n",
    "\n",
    "positions = np.arange(3,13,3)\n",
    "p1 = ax.violinplot(rfe_to_plot, positions = np.sqrt(results['features'].unique()),showextrema=False )\n",
    "\n",
    "for pc in p1['bodies']:\n",
    "    pc.set_facecolor('grey')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_hatch('/')\n",
    "    pc.set_alpha(.99)\n",
    "    \n",
    "add_label(p1, \"RFE\",'/')  \n",
    "positions = np.arange(1, 10, 2)\n",
    "p2 = ax.violinplot(control_burn_to_plot , positions =  np.sqrt(results['features'].unique()),showextrema= False)\n",
    "\n",
    "\n",
    "for pc in p2['bodies']:\n",
    "    pc.set_facecolor('orangered')\n",
    "    pc.set_edgecolor('black')\n",
    "\n",
    "add_label(p2, r'\\textsc{ControlBurn}')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
